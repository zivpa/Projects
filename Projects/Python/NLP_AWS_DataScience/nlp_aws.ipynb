{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "52002Final2020_21.ipynb.txt",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM12sb-kgn7O"
      },
      "source": [
        "# **52002 Final Assignment Spring 2021**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FsuokbThMoM"
      },
      "source": [
        "## **Instructions**\n",
        "\n",
        "Please **read carefuly the instructions**:\n",
        "\n",
        "You should upload to moodle by August 23rd 23:59 *two* files: \n",
        "\n",
        "1. A single `ipynb` file called `<ID>.ipynb` (where `<ID>` is replaced by your `ID` number) filled with your code, text and results, **AFTER** all the commands were run such that we see in the output blocks the results.\n",
        "\n",
        "2. An single `html` file called `<ID>.html` with the complied code including *all output*. Please verify before submitting that you have all the intended output in your generated html. <br> **Note:** Google colab doesn't support conversion to html. Please download your filled `ipynb` notebook and then convert it to html using Jupyter notebook. See instructions [here](https://stackoverflow.com/questions/53460051/convert-ipynb-notebook-to-html-in-google-colab). \n",
        "\n",
        "\n",
        "\n",
        "**Note:** The assignment is **individual**. You may talk to your friends about general topics related to the course, and technical issues (e.g problems connecting to a database). But you should think about the problems and implement your solutions **individually**. If you're not sure, ask the instructors. \n",
        "\n",
        "**How to write your answers:** In addition the code blocks that you should fill in the designated places, you should explain in text blocks your analysis steps and and results before/after the code blocks. Code blocks without any explanations may result in a reduction in grade even if they are correct.\n",
        "\n",
        "\n",
        "**Grading:** The assignment contains four parts, each divided into a few sub-questions. The number of points for each sub-question is listed next to it.\n",
        "The total number of points is $105$. However, the maximal grade for the final assignment is $100$. \n",
        "\n",
        "\n",
        "**Note:** Points from your grade will be deducted for submitting wrong/missing parts of files OR if not submitting the complete generated/complied output. \n",
        "\n",
        "**Note:** Some parts of the code may take a few minutes to run. \n",
        "\n",
        "Be patient. However, don't leave everything to run at the last minute but prepare in advance so your entire notebook runs and finishes on time. \n",
        "\n",
        "If a certain part runs over half an hour this means you're doing something wrong, or that there are connections/other problems with the google colab server. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEoB6rIYLcQ1"
      },
      "source": [
        "### **Libraries and Other Requirements**\n",
        "\n",
        "Please run the following two cells as is without modifications. <br>\n",
        "1. The first contains `pip` install commands to install required python modules. Some errors are expected, they are mainly caused by inconsistent versions.  <br>\n",
        "2. The second contains python code for importing modules and specific classes from them that can be used later in the code. \n",
        "\n",
        "\n",
        "*   `boto3` is the AWS python official module\n",
        "*   `flair` is a natural language processing (NLP) library   \n",
        "*   `nltk` is another natural language toolkit library   \n",
        "*   `sklearn` is a popular python machine learning library\n",
        "\n",
        "\n",
        "You are allowed to include additional modules and commands as you wish. \n",
        "It it is your responsibility to install them, call them appropriately, and describe them if you do. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYrG2NEVlgDb",
        "outputId": "ee03786a-5c6d-4b90-c963-ce8264670a84"
      },
      "source": [
        "# Installing libraries\n",
        "%pip install boto3\n",
        "!pip3 install flair\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.18.29-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 11.4 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.29\n",
            "  Downloading botocore-1.21.29-py3-none-any.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 73.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 78.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.29->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.29->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.29 botocore-1.21.29 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.6\n",
            "Collecting flair\n",
            "  Downloading flair-0.8.0.post1-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 13.5 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.0.0\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 60.1 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.15-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.0)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.1.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.6.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 673 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.26.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=66de192e205d8a2dc1675121c68605919e22baffd50ee4e9bc8d5e62edfe3243\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=cdeebd3905ebab0e8988f36b18c84e5a9882c1c03ab9076ba2fbb514298f8be2\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=b23b41d3e32cef99bbb383d42b91ffdc3518b2e1ec571c85d89548de61b53636\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=5755c266d7e3842f628876be40a7f23878f6db8e665b0e10a1803712663a2fbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=505c52a55eb8a99e3df09e3c8cc7daf7a33adbf3ab14bf00acd3cd3e62bfcd28\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=7056c6813f76e4d7b8b34d40f3407ab0f35206114b3613b56dd7e756a34c32db\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=520d3025b8250e408eabb16fbc7a9f9dba5f13738dffb4a948543d7150c3d0e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built gdown mpld3 overrides segtok sqlitedict ftfy langdetect\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, sacremoses, pyyaml, overrides, huggingface-hub, transformers, torch, sqlitedict, segtok, mpld3, langdetect, konoha, janome, gdown, ftfy, deprecated, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.12 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pyyaml-5.4.1 requests-2.26.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 torch-1.7.1 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT-DJ-8CktLo",
        "outputId": "7cc4b44c-cc62-471f-adab-78d7f246e351"
      },
      "source": [
        "# Importing the AWS module. Allows also to work with and read from zipped files.\n",
        "import boto3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import time\n",
        "\n",
        "# Useful text-preprocessing commands\n",
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "classifier = TextClassifier.load('sentiment-fast') # building sentiment features\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Useful machine-learning commands\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "import matplotlib.pyplot as plt  # for plotting\n",
        "\n",
        "# tic and toc functions for measuring time \n",
        "def tic():\n",
        "    import time\n",
        "    global startTime_for_tictoc\n",
        "    startTime_for_tictoc = time.time()\n",
        "\n",
        "def toc(pName=''):\n",
        "    import time\n",
        "    if 'startTime_for_tictoc' in globals():\n",
        "        delta = time.time() - startTime_for_tictoc\n",
        "        print(\"{}: Elapsed time is \".format(pName) + str(int(delta)) + \" seconds, or \" + str(round(delta/60,2))+ \" minutes\")\n",
        "    else:\n",
        "        delta = -1\n",
        "        print(\"Toc: start time not set\") \n",
        "    return delta"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-26 10:08:49,542 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-fasttext-rnn/sentiment-en-mix-ft-rnn.pt not found in cache, downloading to /tmp/tmpl1ore046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1242007042/1242007042 [00:34<00:00, 35826342.35B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-26 10:09:24,282 copying /tmp/tmpl1ore046 to cache at /root/.flair/models/sentiment-en-mix-ft-rnn.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-26 10:09:28,906 removing temp file /tmp/tmpl1ore046\n",
            "2021-08-26 10:09:29,030 loading file /root/.flair/models/sentiment-en-mix-ft-rnn.pt\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0q8PuEQFceA"
      },
      "source": [
        "## **A general description of the assignment**\n",
        "\n",
        "In this assignment, we will read and analyze a large dataset from the Amazon Web Service (AWS) Simple Storage Service (S3). <br>\n",
        "The data we will work with is the *Amazon Customer Reviews Dataset*, that contains textual data of customer reviews, in addition to the rating of each product (on a scale of $1$ to $5$) and additional features. \n",
        "\n",
        "The four parts of the assignments are: \n",
        "*    **Part 1:** Connecting to the service and reading data\n",
        "*    **Part 2:** Data preprocessing and feature engineering \n",
        "*    **Part 3:** Fitting a classification model to a large dataset \n",
        "*    **Part 4:** Fitting streaming data using Stochastic Gradient Descent\n",
        "\n",
        "#### **About the Data: Amazon Customer Reviews Dataset**  \n",
        "The dataset contains over $130$ million customer reviews vailable to researchers as part of this release, collected from from 1995 until 2015. \n",
        "The data is available in tab-delimited compressed (zipped) `tsv` files in the `amazon-reviews-pds` S3 `bucket` (see later). <br>\n",
        "Each line in the data files corresponds to an individual review (tab delimited).  \n",
        "\n",
        "Bucket: `amazon-reviews-pds`  \n",
        "Tab Separated Values Data pre-fix: `tsv`  \n",
        "\n",
        "The dataset is divided into different product categories, identified by `keys`. For example, a category for `cameras` is represented by the key: <br>\n",
        " `amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz`  \n",
        "  \n",
        "You can find more information about the dataset [here]( https://s3.amazonaws.com/amazon-reviews-pds/readme.html).\n",
        "\n",
        "\n",
        "\n",
        "#### **What is Amazon Web Services S3?**  \n",
        "\n",
        "Amazon Simple Storage Service (Amazon S3, similar to Google Cloud Storage, Azure Blob Storage, ...) is storage for the Internet. It is designed to make web-scale data transfer, reading, writing and computing easier.\n",
        "Amazon S3 provides a simple interface that gives any developer access to the same highly scalable, reliable, fast, and inexpensive data storage infrastructure using code (for example in `python`). <br>\n",
        "However, the S3 file system is not typical, and is built around a key-value/object mapping (key is the location, object is the content and meta data of the file). \n",
        "\n",
        "These key-values are stored in \"folders\" called `buckets`. Buckets are the fundamental containers in Amazon S3 for data storage, and contain `objects` (files). We can store an unlimited amount of data in a bucket, where each object can contain up to 5 TB of data. Each object is stored and retrieved using a unique developer-assigned key.\n",
        "\n",
        "**Objects:**\n",
        "\n",
        "Objects are the fundamental entities stored in Amazon S3. Objects consist of object data and metadata. The data portion is opaque to Amazon S3. The metadata is a set of `name-value` pairs that describe the object. They include some default metadata, such as the date last modified and standard HTTP metadata, such as Content-Type, and also custom metadata specified at the time the object is stored.\n",
        "\n",
        "**Keys:**\n",
        "An `object` is uniquely identified within a `bucket` by a `key` (name) and a `version ID`. Every `object` has exactly one `key`. <br>\n",
        "That is, thee combination of a (`bucket`, `key`, `version ID`) uniquely identifies each `object` (the version ID is optional). \n",
        "\n",
        "We will use commands for downloading or reading lines from an `object` using the `key`.\n",
        "\n",
        "For more information see [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html).\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NLUfidTiMkg"
      },
      "source": [
        "### **Part 1: Connecting to Amazon Web Server and reading data using boto3**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_agDNd2kfL5"
      },
      "source": [
        "In this section we will get familiar with the AWS S3 cloud storage using API modules. We will create a connection to the cloud storage and access the data.  \n",
        "Specifically, we will use the popular `boto3` AWS library for python to connect to the `amazon-reviews-pds` bucket. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHpR9jkDEYPv"
      },
      "source": [
        "**1.(a) [3 pt]** Using `boto3`'s method called `resource`, run the code below create a connection to AWS S3 named `s3conn`, with your `aws_access_key_id` and `aws_secret_access_key`. \n",
        "\n",
        "Add a line defining a variable called `reviews` that points the `s3conn` conncetion to Amazon's `amazon-reviews-pds` data using the `Bucket` method of `boto3`.  Print the `reviews` variable to verify that it represents the `Bucket` with the `amazon-reviews-pds` dataset. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnUMhmEUM4o5"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEqn2axHANhG",
        "outputId": "95b0a66d-ddc8-431c-b3ff-e045d8b39945"
      },
      "source": [
        "# If you have an AWS account, replace these with your key-id and access key:\n",
        "akid = 'AKIA5SWU2IND3QS4UA5S' \n",
        "sak = '9CDABiddu52jA6ROVwUMZSJV8ydpGJuNrLQJ4wdz'\n",
        "\n",
        "# Using boto3's resource method, create a connection to AWS S3 \n",
        "s3conn = boto3.resource(\n",
        "    's3',\n",
        "    aws_access_key_id = akid,\n",
        "    aws_secret_access_key = sak\n",
        ")\n",
        "\n",
        "# Add your code here\n",
        "reviews = s3conn.Bucket('amazon-reviews-pds')  # Connect to a database of Amazon product reviews\n",
        "print(reviews) #Adding a line to print the variable to verify that it represents the Bucket with the amazon-reviews-pds dataset."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s3.Bucket(name='amazon-reviews-pds')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_RC1tjAEppH"
      },
      "source": [
        "**1.(b) [6 pt]** \n",
        "We are only interested in the data within the `tsv` (tab separated values) parent-key (\"folder\"):\n",
        "\n",
        "*   Run the code-cell below to get all the `keys` of the files within the `tsv` parent-key and their respected file size into a dedicated list.  \n",
        "Each key should contain the name of the `object` and the size of the `object` in bytes.\n",
        "*   Filter the keys to include only `tsv` objects containing reviews, and only from the `us`.\n",
        "*   Print the first $15$ elements of the filtered keys list with their sizes in bytes. \n",
        " In addition, print  the total size in GB (rounded to 3 dec. place) of all the objects of type `tsv` from the `us` passing your filtering (zipped).   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBzGsaELL9Kj"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avplr30zzgpt",
        "outputId": "d83fd0ee-870f-4e77-de14-842784852321"
      },
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "keys_list = []\n",
        "for my_bucket_object in reviews.objects.all():\n",
        "    keys_list.append([my_bucket_object.key,my_bucket_object.size])\n",
        "\n",
        "#Creating an array of the filtered keys and suming up the total size \n",
        "filtered_keys = []\n",
        "total_size = 0\n",
        "for x in keys_list: \n",
        "  if \"tsv\" in x[0]:\n",
        "    if \"us\" in x[0] :\n",
        "      filtered_keys.append(x)\n",
        "      total_size += x[1]\n",
        "    if \"US\" in x[0] :\n",
        "      filtered_keys.append(x)\n",
        "      total_size += x[1]\n",
        "\n",
        "\n",
        "print(tabulate(filtered_keys[:15]))\n",
        "\n",
        "print(\"The total size in GB is:\",round(total_size/1000000000, 3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------  ----------\n",
            "tsv/amazon_reviews_multilingual_US_v1_00.tsv.gz            1466965039\n",
            "tsv/amazon_reviews_us_Apparel_v1_00.tsv.gz                  648641286\n",
            "tsv/amazon_reviews_us_Automotive_v1_00.tsv.gz               582145299\n",
            "tsv/amazon_reviews_us_Baby_v1_00.tsv.gz                     357392893\n",
            "tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz                   914070021\n",
            "tsv/amazon_reviews_us_Books_v1_00.tsv.gz                   2740337188\n",
            "tsv/amazon_reviews_us_Books_v1_01.tsv.gz                   2692708591\n",
            "tsv/amazon_reviews_us_Books_v1_02.tsv.gz                   1329539135\n",
            "tsv/amazon_reviews_us_Camera_v1_00.tsv.gz                   442653086\n",
            "tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv.gz  2689739299\n",
            "tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz  1294879074\n",
            "tsv/amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv.gz   253570168\n",
            "tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz          18997559\n",
            "tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz   506979922\n",
            "tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz       27442648\n",
            "---------------------------------------------------------  ----------\n",
            "The total size in GB is: 33.844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rIT4Pnvn2tb"
      },
      "source": [
        "**1.(c) [6 pt]** Using the output of **1.(b)**, create a `pandas` dataframe named `file_categories_df` with the following columns:   \n",
        "<!-- [,,sizeGB] the size of each file: -->\n",
        "\n",
        "*   `category`: the file's (object's) category, parsed from the key string (without unnecessary characters). If there are multiple categories with the same name, use `_00, _01` ... suffixes for different versions\n",
        "*   `size`:  the size in bytes of the file\n",
        "*   `sizeGB`: the size in GB of the file  \n",
        "*   `estSizeGB`: the estimated size in GB of the `uncompressed` file, assuming the gzip compresses a file to size of around `30%` of the original size. \n",
        "    \n",
        "For example, one row of the table should be: <br>\n",
        "`Digital_Software, 18997559, 0.017693, 0.05898`\n",
        "\n",
        "Show the top-10 rows of the created data-frame using the `head` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6a1jCnNMwrq"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "Vxu4WV_ZzVuc",
        "outputId": "b5f2abc0-5824-448a-91ba-4e022c8e657a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Creating a dataframe of the filtered keys of the relevant names of categories without unnecessary characters.\n",
        "file_categories_df = pd.DataFrame(filtered_keys)\n",
        "file_categories_df.loc[1, 0]\n",
        "for i in range(len(file_categories_df.loc[:,0])):\n",
        "   file_categories_df.loc[i, 0] = file_categories_df.loc[i,0][22:][:-13] \n",
        "\n",
        "file_categories_df.loc[0,0] = \"Multilingual\"\n",
        "file_categories_df.loc[47, 0] = \"Sample\"\n",
        "file_categories_df.loc[5,0] += \"_00\"\n",
        "file_categories_df.loc[6,0] += \"_01\"\n",
        "file_categories_df.loc[7,0] += \"_02\"\n",
        "file_categories_df.loc[9,0] += \"_00\"\n",
        "file_categories_df.loc[10,0] += \"_01\"\n",
        "\n",
        "file_categories_df.rename(columns={0:'categories', 1:'size'}, inplace=True)\n",
        "file_categories_df['sizeGB'] = round(file_categories_df['size']/1000000000,3)\n",
        "#Estimated size in GB:\n",
        "file_categories_df['estSizeGB'] = file_categories_df['sizeGB']/0.3\n",
        "\n",
        "#Printing the top 15 rows of the dataframe\n",
        "file_categories_df.head(15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>size</th>\n",
              "      <th>sizeGB</th>\n",
              "      <th>estSizeGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Multilingual</td>\n",
              "      <td>1466965039</td>\n",
              "      <td>1.467</td>\n",
              "      <td>4.890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apparel</td>\n",
              "      <td>648641286</td>\n",
              "      <td>0.649</td>\n",
              "      <td>2.163333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Automotive</td>\n",
              "      <td>582145299</td>\n",
              "      <td>0.582</td>\n",
              "      <td>1.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Baby</td>\n",
              "      <td>357392893</td>\n",
              "      <td>0.357</td>\n",
              "      <td>1.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beauty</td>\n",
              "      <td>914070021</td>\n",
              "      <td>0.914</td>\n",
              "      <td>3.046667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Books_00</td>\n",
              "      <td>2740337188</td>\n",
              "      <td>2.740</td>\n",
              "      <td>9.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Books_01</td>\n",
              "      <td>2692708591</td>\n",
              "      <td>2.693</td>\n",
              "      <td>8.976667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Books_02</td>\n",
              "      <td>1329539135</td>\n",
              "      <td>1.330</td>\n",
              "      <td>4.433333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Camera</td>\n",
              "      <td>442653086</td>\n",
              "      <td>0.443</td>\n",
              "      <td>1.476667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Digital_Ebook_Purchase_00</td>\n",
              "      <td>2689739299</td>\n",
              "      <td>2.690</td>\n",
              "      <td>8.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Digital_Ebook_Purchase_01</td>\n",
              "      <td>1294879074</td>\n",
              "      <td>1.295</td>\n",
              "      <td>4.316667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Digital_Music_Purchase</td>\n",
              "      <td>253570168</td>\n",
              "      <td>0.254</td>\n",
              "      <td>0.846667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Digital_Software</td>\n",
              "      <td>18997559</td>\n",
              "      <td>0.019</td>\n",
              "      <td>0.063333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Digital_Video_Download</td>\n",
              "      <td>506979922</td>\n",
              "      <td>0.507</td>\n",
              "      <td>1.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>27442648</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   categories        size  sizeGB  estSizeGB\n",
              "0                Multilingual  1466965039   1.467   4.890000\n",
              "1                     Apparel   648641286   0.649   2.163333\n",
              "2                  Automotive   582145299   0.582   1.940000\n",
              "3                        Baby   357392893   0.357   1.190000\n",
              "4                      Beauty   914070021   0.914   3.046667\n",
              "5                    Books_00  2740337188   2.740   9.133333\n",
              "6                    Books_01  2692708591   2.693   8.976667\n",
              "7                    Books_02  1329539135   1.330   4.433333\n",
              "8                      Camera   442653086   0.443   1.476667\n",
              "9   Digital_Ebook_Purchase_00  2689739299   2.690   8.966667\n",
              "10  Digital_Ebook_Purchase_01  1294879074   1.295   4.316667\n",
              "11     Digital_Music_Purchase   253570168   0.254   0.846667\n",
              "12           Digital_Software    18997559   0.019   0.063333\n",
              "13     Digital_Video_Download   506979922   0.507   1.690000\n",
              "14        Digital_Video_Games    27442648   0.027   0.090000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u1crB4VFNRt"
      },
      "source": [
        "\n",
        "**1.(d) [6 pt]** **Reading the Data:**    \n",
        "*   Run the code cell below using the `download_file` method for the `bucket` of `s3conn`, to download the file of one of the six *smallest* categories (size < `30MB`) into the colab/local file-system, and read the entire file into a dataframe.\n",
        "\n",
        "*   Read the entire data from the category into a pandas dataframe called `df` \n",
        "and print the number of rows (data points) and columns (features). \n",
        "\n",
        "*   Compute and print the average size in bytes of each data point (an amazon product review). <br>\n",
        "Next, use this number and the total size of the entire dataset computed in **1.(b)**, to estimate the total number of reviews in the entire dataset over all categories. <br> \n",
        "How close is it to $130$ million? explain what can cause the difference in numbers.\n",
        "\n",
        "*   Apply `df.head(5)` to view the start of the data-frame.\n",
        "\n",
        "\n",
        "**Note:** during code development, it is allowed here and in other sub-questions (and even recommended) to limit the size of what we load into memory. However, for submission, the full files/requested data sizes should be used. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aUXC1TMOId1"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjIQdIuuoIBv",
        "outputId": "bba7dabb-e330-461b-a5e1-d477309929af"
      },
      "source": [
        "#Using the filtered keys created earlier and downloading the Digital_Video_Games file.\n",
        "keys_list = filtered_keys\n",
        "print('file to read/stream: ', keys_list[14][0]) \n",
        "fileToStream = keys_list[14][0]\n",
        "\n",
        "s3conn.Bucket('amazon-reviews-pds').download_file(fileToStream, 'tmp.gz')\n",
        "% ls /content/ -lah\n",
        "\n",
        "with gzip.open('/content/tmp.gz', 'rb') as f_in:\n",
        "    tmp = f_in.readlines() # Reading lines into a python object\n",
        "\n",
        "df = pd.DataFrame(tmp) #Creating dataframe\n",
        "df[0] = df[0].str.decode(\"utf-8\")\n",
        "#Splitting the columns\n",
        "df[[\"marketplace\", \"customer_id\", \"review_id\", \"product_id\",\"product_parent\", \"product_title\", \"product_category\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\", \"verified_purchase\",\"review_headline\",\"review_body\", \"review_date\"]] = df[0].str.split(\"\\t\",expand=True,)\n",
        "df = df.iloc[1:,1:]\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n",
            "total 27M\n",
            "drwxr-xr-x 1 root root 4.0K Aug 26 10:09 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Aug 26 09:49 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Aug 13 13:34 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Aug 13 13:35 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root  27M Aug 26 10:09 tmp.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nms4OO57x3DY",
        "outputId": "660b5cb0-ff7b-491e-9320-ec7ffbadc5d4"
      },
      "source": [
        "print(\"The number of rows is\", len(df['customer_id']), \"and the of columns is\", len(df.columns))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of rows is 145431 and the of columns is 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ8VR7kJrdjs",
        "outputId": "ddab951d-d974-450d-ca4b-6e0a03affae2"
      },
      "source": [
        "avg_row_size = round(file_categories_df['size'][14]/len(df['customer_id']),3)\n",
        "print(\"The average size of each review of this data category is:\",avg_row_size)\n",
        "\n",
        "est_reviews = total_size/avg_row_size\n",
        "print(\"The estimated number of reviews in this category is:\", est_reviews)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average size of each review of this data category is: 188.699\n",
            "The estimated number of reviews in this category is: 179355880.59290192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_oZn98ztxbv"
      },
      "source": [
        "As we can see, the actual number of reviews is smaller than the estimated one. This is due to the fact that in this category people tend to write longer reviews. The category is Digital_Video_Games\tand people who write reviews are probably mostly gamers or fans of digital video games. And so, it is plausible that they would have much to say about digital video games. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW493yPkkktC"
      },
      "source": [
        "#Striping the review date from unnecessary characters.\n",
        "df[\"review_date\"] = df[\"review_date\"].str.strip()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "XIh8EQSH-PhG",
        "outputId": "8892e196-3298-4b17-f659-689b9d0d493d"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace  ... review_date\n",
              "1          US  ...  2015-08-31\n",
              "2          US  ...  2015-08-31\n",
              "3          US  ...  2015-08-31\n",
              "4          US  ...  2015-08-31\n",
              "5          US  ...  2015-08-31\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a9h5Y56uz27"
      },
      "source": [
        "### **Part 2: Data preprocessing and feature engineering**\n",
        "\n",
        "In this part we use the textual data to create predictive features, and preprocess additional features, to prepare the data-frame to be used in training a classifier. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPxcAQUY0Ifz"
      },
      "source": [
        "**2.(a) [7 pt]** Apply the following common text normalization and standardization steps to the `review_body` textual column. It is recommended to use the `nltk` package:\n",
        "     \n",
        "1. Create a new column named `reviews_processed`, and assign it the `review_body` strings, just with all characteres as lower-case letters. All the following transformations should be done on the `reviews_processed` column. \n",
        "2. Split to words using the `word_tokenize` method.\n",
        "3. Keep only alpha-numerical values  (you can use `str.isalpha()`). \n",
        "4. Unite together words with similar meanining using the `WordNetLemmatizer` command.\n",
        "5. Remove non-informative words (stop-words) using the `stopwords` command\n",
        "6. Finally, join back all the tokens (words) to a single string for each row. \n",
        "7. Remove from `review_processed` rows with empty strings of `review_body`.      \n",
        "\n",
        "Write first a function that recieves as input a data-frame and modifies it according to the steps below. Then, apply the function to the `df` dataframe. \n",
        "\n",
        "Show the top-10 records using the command `df.reviews_processed.head(10)` once you are done. \n",
        "\n",
        "**Note:** Running the commands for this sub-questions may take a few minutes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA9sE3_ftgf0",
        "outputId": "6662aca0-0353-4aaa-fc2c-31ea840a75d2"
      },
      "source": [
        "#Building helpful functionts to help us process the reviews\n",
        "\n",
        "def isalpha_func(txt):\n",
        "  text = []\n",
        "  [text.append(x) for x in txt if x.isalpha]\n",
        "  return text\n",
        "\n",
        "def lemmatizing(txt):\n",
        "  text = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  [text.append(lemmatizer.lemmatize(x)) for x in txt]\n",
        "  return text\n",
        "\n",
        "def stop_w(txt):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  text = []\n",
        "  [text.append(x) for x in txt if x not in stop_words]\n",
        "  return text\n",
        "\n",
        "#Applying all functions to a dataframe and using it on our dataframe\n",
        "def modifier(df):\n",
        "  df[\"reviews_processed\"] = df.loc[:,\"review_body\"].str.lower()  #Lower casing all characters.\n",
        "  df[\"reviews_processed\"] = df[\"reviews_processed\"].apply(word_tokenize) #Word tokenizing - seperating each sentence to a list of words.\n",
        "  df[\"reviews_processed\"] = df[\"reviews_processed\"].apply(isalpha_func) #Keeping only alpha-numerical values.\n",
        "  df[\"reviews_processed\"] = df[\"reviews_processed\"].apply(lemmatizing) #Uniting together words with similar meanining \n",
        "  df[\"reviews_processed\"] = df[\"reviews_processed\"].apply(stop_w) #Removing non-informative words using the stopwords command\n",
        "  df[\"reviews_processed\"] = [\" \".join(item) for item in df[\"reviews_processed\"]] #Joining back all the words to a single string for each row.\n",
        "  df = df[df.reviews_processed != \"\"] #Removing from the dataframe rows with empty strings.\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  return df\n",
        "\n",
        "df = modifier(df)\n",
        "df.reviews_processed.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    keep buying madden every year hoping get back ...\n",
              "1                                              awesome\n",
              "2    prepping end world one thing installed your-en...\n",
              "3                                              perfect\n",
              "4                                            awesome !\n",
              "5                                            awesome !\n",
              "6    like new skill like herbalism , camping fun . ...\n",
              "7                                                super\n",
              "8                        excellent , fast secure ! ! !\n",
              "9                                                   ok\n",
              "Name: reviews_processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etxHLWfY9_3Q"
      },
      "source": [
        "**2.(b) [6 pt]** **Sentiment analysis using the `flair` library:** \n",
        "We next want to add *sentiment* features to each review, that use a pre-trained model to predict if the review text is positive or negative. Note that we use this only as a way for defining new predictive features from the text. We will train our actual classifier in **Part 3**.\n",
        "\n",
        "1. *Execute* the cells below with the command: <br> \n",
        " `classifier = TextClassifier.load('sentiment-fast')` <br>\n",
        " to load the a pre-trained text classifier object\n",
        "\n",
        "2. Next, Loop over the first $10$ reviews and for each one \n",
        "apply `flair`'s `Sentence` method on the processed review text, an input the resulting sentence to the `classifier.predict()` method. \n",
        "Print for the first $10$ reviews out both the reviews and their sentiment (`NEGATIVE/POSITIVE` and the sentiment score). Do the generated sentiments represent the text? \n",
        "\n",
        "3. How long does it take to compute the sentiments of `100, 1,000`, and `10,000` datapoints in this manner? (do not print them, but make sure that the sentiments are actually computed). Extrapolate and estimate how long would it take to compute the sentiments over *all* data points in your category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1damM0KCO3aJ"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-X9TFvq-RrM",
        "outputId": "a6de1a21-6036-419c-8df6-353c56403530"
      },
      "source": [
        "classifier = TextClassifier.load('sentiment-fast')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-26 10:12:05,828 loading file /root/.flair/models/sentiment-en-mix-ft-rnn.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqVkpgT2MxKW"
      },
      "source": [
        "#Creating lists of sentiments score and value the first 10 reviews.\n",
        "sentiment = []\n",
        "confidence = []\n",
        "for i in range(0,10):\n",
        "  sample = Sentence(df[\"reviews_processed\"].iloc[i])\n",
        "  classifier.predict(sample)\n",
        "\n",
        "  sentiment.append(sample.labels[0].value)\n",
        "  confidence.append(sample.labels[0].score)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhPwXvveQ-qv",
        "outputId": "be81f56d-1567-4a12-b690-46fdf4b6a4a2"
      },
      "source": [
        "#Creating a dataframe with the reviews and their sentiments\n",
        "flair_classifier_df = pd.DataFrame()\n",
        "flair_classifier_df['sentence'] = df['reviews_processed'].head(10)\n",
        "flair_classifier_df['sentiment'] = sentiment\n",
        "flair_classifier_df['confidence'] = confidence\n",
        "print(flair_classifier_df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            sentence sentiment  confidence\n",
            "0  keep buying madden every year hoping get back ...  NEGATIVE    0.999833\n",
            "1                                            awesome  POSITIVE    0.997095\n",
            "2  prepping end world one thing installed your-en...  POSITIVE    0.910985\n",
            "3                                            perfect  POSITIVE    0.994086\n",
            "4                                          awesome !  POSITIVE    0.998940\n",
            "5                                          awesome !  POSITIVE    0.998940\n",
            "6  like new skill like herbalism , camping fun . ...  POSITIVE    0.952463\n",
            "7                                              super  POSITIVE    0.950873\n",
            "8                      excellent , fast secure ! ! !  POSITIVE    0.998816\n",
            "9                                                 ok  POSITIVE    0.563957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfnKz5oKVJhv"
      },
      "source": [
        "As we can easily see, the generated sentiments represent the actual text. When the review is positive we get a POSITIVE sentiment with a high confidence value and when the review is pretty negative we get a high value of NEGATIVE sentiment. Note that, when the review is not entirely positive or negative we get a low confidence value. In these cases we know that the review is pretty neutral with a slightly more positive/negative attitude. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMjNlKR4qRCR",
        "outputId": "7214f46f-5b9a-4ccf-d998-d652534f3df0"
      },
      "source": [
        "#Checking the running time of the computation of the sentiments of 100, 1,000, and 10,000 datapoints.\n",
        "tic()\n",
        "for i in range(0,100):\n",
        "  sample = Sentence(df[\"reviews_processed\"].iloc[i])\n",
        "  classifier.predict(sample)\n",
        "d = toc()\n",
        "print(\"Running time for 100 datapoints in this manner is:\", d)\n",
        "\n",
        "tic()\n",
        "for i in range(0,1000):\n",
        "  sample = Sentence(df[\"reviews_processed\"].iloc[i])\n",
        "  classifier.predict(sample)\n",
        "d = toc()\n",
        "print(\"Running time for 1000 datapoints in this manner is:\", d)\n",
        "\n",
        "tic()\n",
        "for i in range(0,10000):\n",
        "  sample = Sentence(df[\"reviews_processed\"].iloc[i])\n",
        "  classifier.predict(sample)\n",
        "d = toc()\n",
        "print(\"Running time for 10000 datapoints in this manner is:\", d)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ": Elapsed time is 0 seconds, or 0.01 minutes\n",
            "Running time for 100 datapoints in this manner is: 0.3426094055175781\n",
            ": Elapsed time is 4 seconds, or 0.07 minutes\n",
            "Running time for 1000 datapoints in this manner is: 4.197623014450073\n",
            ": Elapsed time is 44 seconds, or 0.74 minutes\n",
            "Running time for 10000 datapoints in this manner is: 44.27806496620178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAl4CJLpzSQT"
      },
      "source": [
        "By the logic of the running time above, the running time of 100,000 datapoints would take approximately 478 seconds (8 min) and for the entire data, it would take approx one hour and 20 minutes (4,780 seconds). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tugmwslS8nW"
      },
      "source": [
        "**2.(c) [6 pt]** To speed up the sentiment retrieval, we would like to implement a `mini-batch` approach: \n",
        "We first create a list of sentences `Sentence(text)``s for all input texts, \n",
        "and then go over them in groups of size `mini_batch_size`, and apply the `.predict` function to the entire  `mini-batch` instead of $1$ data-point at a time: \n",
        "\n",
        "1. Define a `batch` function that has an iterable and a `mini-batch` size `int` as inputs, and yields out the mini-batches of the iterable. \n",
        "\n",
        "2. Define a `get_sentiment` function that takes an `np.array` of text datapoints as input, and outputs a `np.array` of the label objects from the sentiments. Make sure you use the `mini_batch_size=128` and `verbose=True` parameters within the `.predict` method. Also, make sure you call the `.predict` method only once, on a list of `Sentence` objects. \n",
        "\n",
        "3. Run the above functions on all the processed text datapoints of `df` using a `mini_batch_size` of `128`, and a `batch size` of `10,000`. Print out the total time it takes and compare it to the predicted time from **2.(b)**.\n",
        "\n",
        "4. Add both the sentiments' scores  (`sent_score`) and the sentiments' values (`sent_value`) as new separate colomns (new features) in `df`. \n",
        "\n",
        "Execute a `df.head()` command to view the top values when done. \n",
        "\n",
        "**Note:** Running the functions on all data points may take a few minutes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_pL2AybrU12"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mni5O3Sj0w98"
      },
      "source": [
        "#Creating a batch function as a generator which inputs data and mini batch size(int) and yields a (mini) batch (of the input size) for each call. \n",
        "def batch_func(data, batch_size): \n",
        "  x = 0 \n",
        "  while x + batch_size <= len(data): \n",
        "    yield np.array(data[x:x + batch_size]) \n",
        "    x = x + batch_size \n",
        "  yield np.array(data[x:]) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6FrsjJlW_0"
      },
      "source": [
        "#Creating a get_sentiment function which gets an array of texts, and outputs the label objects from the sentiments for each row of the array using the classifier from before.\n",
        "def get_sentiment(arr): \n",
        "  sentence = [Sentence(x) for x in arr]\n",
        "  classifier.predict(sentence, mini_batch_size=128 ,verbose=True)\n",
        "  value = [x.labels[0].value for x in sentence]\n",
        "  score = [round(x.labels[0].score,5) for x in sentence]\n",
        "  return np.array([value, score]) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_t10K8cmkwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5882a25-b227-4f05-fffd-17c6857337c0"
      },
      "source": [
        "#Calculating the running time of geting the sentiments to 10,000 datapoints using the batch method.\n",
        "mini_batch_gen = next(batch_func(df, 10000))[:,15]\n",
        "tic()\n",
        "get_sentiment(np.array(mini_batch_gen)) \n",
        "print(\"The running time with the mini batch method in this case is\", round(toc(),3))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ": Elapsed time is 25 seconds, or 0.42 minutes\n",
            "The running time with the mini batch method in this case is 25.344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA472sJft-az"
      },
      "source": [
        "As we can see, the mini batch method is **way** faster in running time than the predicted time from 2(b)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OfMTTHD2cVk"
      },
      "source": [
        "#Turning list of lists to one list\n",
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVtArg-W01hM",
        "outputId": "32a64a02-eb8f-4f49-bb57-4eeb0b67117a"
      },
      "source": [
        " #Creating the relevant columns using previous functions and adding them to our dataframe one batch (10,000 datapoints) at a time\n",
        " def sent(data_frame):\n",
        "  sent_value = [get_sentiment(x)[0] for x in batch_func(data_frame[\"reviews_processed\"], batch_size= 10000)]\n",
        "  sent_value = [arr.tolist() for arr in sent_value]\n",
        "  sent_value = flatten(sent_value)\n",
        "  data_frame[\"sent_value\"] = sent_value\n",
        "\n",
        "  sent_score = [get_sentiment(x)[1] for x in batch_func(data_frame[\"reviews_processed\"], batch_size= 10000)]\n",
        "  sent_score = [arr.tolist() for arr in sent_score]\n",
        "  sent_score = flatten(sent_score)\n",
        "  data_frame[\"sent_score\"] = sent_score\n",
        "\n",
        "  return data_frame\n",
        "\n",
        "#Calling the function and applying it to our dataframe\n",
        "df = sent(df)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:22<00:00,  3.54it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:21<00:00,  3.74it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:24<00:00,  3.28it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:23<00:00,  3.40it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:41<00:00,  1.89it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:38<00:00,  2.04it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:45<00:00,  1.75it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:42<00:00,  1.86it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:45<00:00,  1.73it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:54<00:00,  1.45it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:45<00:00,  1.75it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [01:09<00:00,  1.14it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [01:05<00:00,  1.21it/s]\n",
            "Inferencing on batch 42: 100%|██████████| 42/42 [00:37<00:00,  1.13it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.79it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:22<00:00,  3.52it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:19<00:00,  4.02it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:23<00:00,  3.30it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:24<00:00,  3.25it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:42<00:00,  1.88it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:38<00:00,  2.04it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:44<00:00,  1.77it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:44<00:00,  1.79it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:54<00:00,  1.45it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:45<00:00,  1.75it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [01:09<00:00,  1.13it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [01:05<00:00,  1.21it/s]\n",
            "Inferencing on batch 42: 100%|██████████| 42/42 [00:37<00:00,  1.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCo1-TVgDkHA"
      },
      "source": [
        "It is important to note that the whole idea of using the batch method is in order to save amount of space. Using the same action over 10,000 datapoints at a time may result in decreasing the accuracy of our models but is saves memory space, which is extremely helpful dealing with big data.\n",
        " **This is the whole point of this project**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "r9F1A-wkB3tF",
        "outputId": "2cdfa531-93ca-4cf2-b8f9-a647e63d0819"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>sent_value</th>\n",
              "      <th>sent_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>keep buying madden every year hoping get back ...</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.99983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.99709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>prepping end world one thing installed your-en...</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.91099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>perfect</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.99409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome !</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>0.99894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace customer_id  ... sent_value sent_score\n",
              "0          US    21269168  ...   NEGATIVE    0.99983\n",
              "1          US      133437  ...   POSITIVE    0.99709\n",
              "2          US    45765011  ...   POSITIVE    0.91099\n",
              "3          US      113118  ...   POSITIVE    0.99409\n",
              "4          US    22151364  ...   POSITIVE    0.99894\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-M-kX2Alj51"
      },
      "source": [
        "**2.(d) [8 pt] Setting binary variables:** \n",
        "\n",
        "Write a function that modifies a `pandas` data-frame as follows:\n",
        "\n",
        "*   To simplify the target variable and get a binary classification problem, map star ratings of `1,2` to `0`, and `4,5` to `1` (i.e. `0` will represent a positive review and `1` will represent a negative review). Filter out neutral star ratings of `3`.\n",
        "\n",
        "In addition:\n",
        "\n",
        "*   Make sure the types of the data is compatible with modeling\n",
        "*   Set binary variables values to zero/one where applicable\n",
        "*   Get rid of `np.nan, np.inf, -np.inf`\n",
        "\n",
        "Run the function on the data-frame `df` and then run `df.head()` to view the top values when done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT2S479spoNw"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBB2I31mOXZU"
      },
      "source": [
        "#Modifying our dataframe and creating an explained binary variable \"binstar\".\n",
        "def modify(df):\n",
        "  #Creating 'binstar' variable using star_rating column values classified to 0 for positive and 1 for negative reviews.\n",
        "  dictionary = {\"1\":0, \"2\":0, \"4\":1, \"5\":1}\n",
        "  df['binstar'] = df['star_rating'].map(dictionary)\n",
        "  df = df.dropna()\n",
        "  #Classifying sent_value column to 0 and 1 so it could be included in our future model.\n",
        "  df['sent_value'] = df['sent_value'].map({\"POSITIVE\":0,\"NEGATIVE\":1})\n",
        "  df = df.dropna()\n",
        "  #Varifying that all relevant columns are integers.\n",
        "  df[[\"helpful_votes\", \"total_votes\", \"sent_score\", \"sent_value\"]] = df[[\"helpful_votes\", \"total_votes\", \"sent_score\", \"sent_value\"]].apply(pd.to_numeric)\n",
        "  return df\n",
        "\n",
        "#Applying the function to our dataframe\n",
        "df = modify(df)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "ovry2FpO2H3t",
        "outputId": "b075c1dd-ac00-46eb-aed6-75628229cf55"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews_processed</th>\n",
              "      <th>sent_value</th>\n",
              "      <th>sent_score</th>\n",
              "      <th>binstar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>21269168</td>\n",
              "      <td>RSH1OZ87OYK92</td>\n",
              "      <td>B013PURRZW</td>\n",
              "      <td>603406193</td>\n",
              "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>A slight improvement from last year.</td>\n",
              "      <td>I keep buying madden every year hoping they ge...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>keep buying madden every year hoping get back ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.99983</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>133437</td>\n",
              "      <td>R1WFOQ3N9BO65I</td>\n",
              "      <td>B00F4CEHNK</td>\n",
              "      <td>341969535</td>\n",
              "      <td>Xbox Live Gift Card</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99709</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>45765011</td>\n",
              "      <td>R3YOOS71KM5M9</td>\n",
              "      <td>B00DNHLFQA</td>\n",
              "      <td>951665344</td>\n",
              "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Hail to the great Yuri!</td>\n",
              "      <td>If you are prepping for the end of the world t...</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>prepping end world one thing installed your-en...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.91099</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>113118</td>\n",
              "      <td>R3R14UATT3OUFU</td>\n",
              "      <td>B004RMK5QG</td>\n",
              "      <td>395682204</td>\n",
              "      <td>Playstation Plus Subscription</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>perfect</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99409</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>22151364</td>\n",
              "      <td>RV2W9SGDNQA2C</td>\n",
              "      <td>B00G9BNLQE</td>\n",
              "      <td>640460561</td>\n",
              "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
              "      <td>Digital_Video_Games</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>Awesome!</td>\n",
              "      <td>2015-08-31</td>\n",
              "      <td>awesome !</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99894</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  marketplace customer_id       review_id  ... sent_value sent_score binstar\n",
              "0          US    21269168   RSH1OZ87OYK92  ...          1    0.99983     0.0\n",
              "1          US      133437  R1WFOQ3N9BO65I  ...          0    0.99709     1.0\n",
              "2          US    45765011   R3YOOS71KM5M9  ...          0    0.91099     1.0\n",
              "3          US      113118  R3R14UATT3OUFU  ...          0    0.99409     1.0\n",
              "4          US    22151364   RV2W9SGDNQA2C  ...          0    0.99894     1.0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPQf05iY3si_"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgurFap3fwv2"
      },
      "source": [
        "**2.(e) [1 pt]** In addition to the `flair` sentiment features we would like to add also a `TfidfVectorizer` feature. \n",
        "\n",
        "Run the code cell below to create a numpy array named `final_df` that will be used for modeling in **Part 3**. Add a line printing the shape (number of samples and features) of the resulting array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1iV4L247A3h"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u26cREvfx78H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d83c01c-0cb2-433c-9b02-02effd2fe43d"
      },
      "source": [
        "# Adding the features of the dataframe that we want to transform and/or combine. We will add also 'binstar'.\n",
        "mapper = DataFrameMapper([\n",
        "     ('reviews_processed', TfidfVectorizer(max_features=100)),\n",
        "     ('helpful_votes', None),\n",
        "     ('total_votes', None),\n",
        "     ('sent_score', None),\n",
        "     ('sent_value', None),\n",
        "     ('binstar', None)\n",
        " ], df_out=False)\n",
        "\n",
        "\"\"\"\n",
        "Use the fit_transform method to transform the old dataframe into a new one\n",
        "that can be fed to the machine learning algorithm.\n",
        "\"\"\"\n",
        "mapper_fit = mapper.fit(df)\n",
        "final_df = mapper.transform(df) # a numpy array \n",
        "\n",
        "print(final_df.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(133750, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MY03KFrW3i3"
      },
      "source": [
        "### **Part 3: Fitting a classification model to a large dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc_D7bB8vTi_"
      },
      "source": [
        "Our goal is to predict the binarized star rating (`binstar`) variable using the other features for each review.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cLgIus0hpDN"
      },
      "source": [
        "**3.(a) [6 pt]** Create a `x_train,x_test,y_train,y_test` random split of the `final_df` and the target `binstar`, with the test set containing $20\\%$ of the data and the training set containing $80\\%$ of the data. \n",
        "\n",
        "In addition, normalize/standardize the data as you wish. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5RSAN_7l7lZ"
      },
      "source": [
        "df_final = pd.DataFrame(final_df)\n",
        "df_final = df_final.reset_index(drop=True) \n",
        "\n",
        "#Creating y and x seperately so we could normalize and split to train and test\n",
        "binstar = df_final.iloc[:,-1]\n",
        "X = df_final.iloc[:,:-1]\n",
        "\n",
        "X = preprocessing.normalize(X)\n",
        "X = pd.DataFrame(X)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i9qwsn9IhO7"
      },
      "source": [
        "Note that, I chose to normalize the data because our data is not normaly distributed (and maybe even non iid).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myldTIas8cfQ",
        "outputId": "4d9d59de-29a7-4f41-f898-260114c064b0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, binstar, test_size=0.2, random_state=42)\n",
        "print('Training set size: {0:d}\\nTest set size: {1:d}'.format(len(x_train),len(x_test)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: 107000\n",
            "Test set size: 26750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_fjhfeui1Sn"
      },
      "source": [
        "**3.(b) [5 pt]** Fit a logistic regression model to the training set. \n",
        "You may use the `sklearn` package. Print the train and test model accuracy\n",
        "<!-- *   Report the precision, recall, and f1-score and explain each metric. -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9o9eRxa_4tj"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTKJwTYYDnx7",
        "outputId": "3341ae93-03ae-4503-e2cf-88ea3839b4af"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "#Fitting logistic regression\n",
        "lr = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
        "lr.fit(x_train,y_train)\n",
        "print('Regression finished with R^2={0:f}'.format(lr.score(x_train,y_train)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regression finished with R^2=0.879037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wQXuYeTaFSO"
      },
      "source": [
        "#Creating a useful function that prints out several indicative results of a model. \n",
        "def model_results(y,y_hat):\n",
        "  cm=confusion_matrix(y,y_hat)\n",
        "  pre=precision_score(y,y_hat)\n",
        "  rec=recall_score(y,y_hat)\n",
        "  f1=f1_score(y,y_hat)\n",
        "  auc=roc_auc_score(y,y_hat)\n",
        "  accuracy = accuracy_score(y, y_hat)\n",
        "\n",
        "  print(f'Precision score: {pre:3.3f}')\n",
        "  print(f'Recall score: {rec:3.3f}')\n",
        "  print(f'F1 score: {f1:3.3f}')\n",
        "  print(f'AUC score: {auc:3.3f}')\n",
        "  print(f'Accuracy: {accuracy:3.3f}')\n",
        "  print('Confusion matrix:')\n",
        "  print(cm)\n",
        "  return cm"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "-FMhplKrJrld",
        "outputId": "271157b9-f019-46f3-d5e3-251a44e5f69b"
      },
      "source": [
        "#Test\n",
        "model = lr.fit(x_train,y_train)\n",
        "predictions = model.predict(x_test)\n",
        "cm = model_results(y_test,predictions)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sn.heatmap(cm, annot=True,fmt=\"d\",annot_kws={\"size\": 16}) # font size\n",
        "plt.xlabel('Predicted Label'); plt.ylabel('True Label');"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.913\n",
            "Recall score: 0.926\n",
            "F1 score: 0.919\n",
            "AUC score: 0.830\n",
            "Accuracy: 0.878\n",
            "Confusion matrix:\n",
            "[[ 4877  1769]\n",
            " [ 1491 18613]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCHz_N8jKKO0"
      },
      "source": [
        "The test accuracy is high"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "gIcJwmbm_LYT",
        "outputId": "c11e31f2-17c7-4c49-f58b-5b759fa83e6c"
      },
      "source": [
        "#Train\n",
        "train_pred = model.predict(x_train)\n",
        "cm = model_results(y_train,train_pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sn.heatmap(cm, annot=True,fmt=\"d\",annot_kws={\"size\": 16}) # font size\n",
        "plt.xlabel('Predicted Label'); plt.ylabel('True Label');"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.916\n",
            "Recall score: 0.925\n",
            "F1 score: 0.920\n",
            "AUC score: 0.830\n",
            "Accuracy: 0.879\n",
            "Confusion matrix:\n",
            "[[19155  6909]\n",
            " [ 6034 74902]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV7R-6uXKZUx"
      },
      "source": [
        "Train accuracy is also high"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4N7Dh0omE3"
      },
      "source": [
        "So far, it seems that the model works fine and has good results (as we see from the tests above). For example, the accuracy is above 0.85 which is a high accuracy value. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7U-BnmJkMx-"
      },
      "source": [
        "**3.(c) [6 pt]** For different lengths of $n = 10 \\times 2^k$, for $k=0,1,..,14$ extract only the first $n$ values in the train set (i.e. first rows of `x_train` and first values of `y_train`) and use them to fit the logistic regression model. (If $n$ is larger than the total number of rows, set $n$ to the actua number).\n",
        "\n",
        "Plot the training error (for each $k$ on the appropriate train set) and test error (on the entire test set) vs. the sample size $n$ shown on a log-scale. Do we see an improvement when increasing $n$? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoO-mmLE_03I"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zusasoJaSF_"
      },
      "source": [
        "#Creating list of n's and lists of test and training errors\n",
        "n = [10*2**k for k in range(0,14)]\n",
        "training_error = []\n",
        "test_error = []\n",
        "for x in n:\n",
        "  train_x = x_train.iloc[:x,]\n",
        "  train_y = y_train.iloc[:x,]\n",
        "  model_fit = lr.fit(train_x,train_y)\n",
        "\n",
        "  training_error.append(1 - model_fit.score(train_x, train_y))\n",
        "  test_error.append(1 - model_fit.score(x_test,y_test))\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtlhbWGTyRPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "9efedcfa-4ffd-4c01-b833-bc117bb1aba6"
      },
      "source": [
        "#Creating a dataframe for the plot\n",
        "plot_error_df = pd.DataFrame(dict(log_N= np.log(n), training_error=training_error, test_error = test_error))\n",
        "plot_error_df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>log_N</th>\n",
              "      <th>training_error</th>\n",
              "      <th>test_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.302585</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.248449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.995732</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.248449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.688879</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.248449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.382027</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.248486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.075174</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.181794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.768321</td>\n",
              "      <td>0.106250</td>\n",
              "      <td>0.165458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.461468</td>\n",
              "      <td>0.114062</td>\n",
              "      <td>0.154916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.154615</td>\n",
              "      <td>0.118750</td>\n",
              "      <td>0.144411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.847763</td>\n",
              "      <td>0.124219</td>\n",
              "      <td>0.137869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8.540910</td>\n",
              "      <td>0.128320</td>\n",
              "      <td>0.132935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9.234057</td>\n",
              "      <td>0.124609</td>\n",
              "      <td>0.129533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>9.927204</td>\n",
              "      <td>0.121094</td>\n",
              "      <td>0.125869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10.620351</td>\n",
              "      <td>0.122388</td>\n",
              "      <td>0.123963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11.313498</td>\n",
              "      <td>0.121509</td>\n",
              "      <td>0.122617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        log_N  training_error  test_error\n",
              "0    2.302585        0.100000    0.248449\n",
              "1    2.995732        0.200000    0.248449\n",
              "2    3.688879        0.175000    0.248449\n",
              "3    4.382027        0.200000    0.248486\n",
              "4    5.075174        0.125000    0.181794\n",
              "5    5.768321        0.106250    0.165458\n",
              "6    6.461468        0.114062    0.154916\n",
              "7    7.154615        0.118750    0.144411\n",
              "8    7.847763        0.124219    0.137869\n",
              "9    8.540910        0.128320    0.132935\n",
              "10   9.234057        0.124609    0.129533\n",
              "11   9.927204        0.121094    0.125869\n",
              "12  10.620351        0.122388    0.123963\n",
              "13  11.313498        0.121509    0.122617"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOX1LVWz6bE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "071a8813-8753-4581-fedb-f7746c60990a"
      },
      "source": [
        "ax1 = plot_error_df.plot(kind='line', x=\"log_N\", y=\"training_error\", color='r', alpha = 0.5)    \n",
        "ax2 = plot_error_df.plot(kind='line', x=\"log_N\", y=\"test_error\", color='b', ax=ax1, alpha = 0.5) \n",
        "plt.title('Train & Test errors vs log of Sample size n')\n",
        "plt.xlabel('Log(n)')\n",
        "plt.ylabel('errors')\n",
        "plt.legend([\"training error\", \"test error\"], loc =\"upper right\")\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe5dadad950>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0O_AIngcSv6"
      },
      "source": [
        "As we can see in the graph above, the **more** amount of data we use the **less** error we have in our model. The train error is always under the test error. \n",
        "\n",
        "*It seems like the train error is not stable and not consistant with n. I do not know what is the reason for this. I tried several changes in the code above which resulted in even more extreme results.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e78AxxLkbri"
      },
      "source": [
        "**3.(d) [9 pt] Combining models from similar data:** \n",
        "\n",
        "* Find the maximal power $k$ such that the test error for $n = 10 \\times 2^k$ is at least $0.02$ higher than the test error for the maximal $n$ (denoted $n_{max}$ you have used in **3.(c)**.\n",
        "\n",
        "* Split the maximal training set you have used into $n_{max} / n$ random blocks of equal size. \n",
        "\n",
        "* Run a logistic regression model on each block separately\n",
        "\n",
        "* Finally, average the fitted models coefficients to get a combined model. \n",
        "\n",
        "* Report the train and test accuracy for the combined model on the entire (unified) training and test set.  \n",
        "\n",
        "* How does it compare to the results from the **3.(c)** where fitting the model using the entire dataset? is the accuracy diminished/comparable/improved?\n",
        "\n",
        "* At what circumstances would you recommend this approach of splitting the data to blocks and combining the models?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3p8aV9THBo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c16ec4f-693a-49e2-bbf7-c69e117fa841"
      },
      "source": [
        "#Finding the maximal power k such that the test error for n=10×2k is at least 0.02 higher than the test error for the maximal n\n",
        "\n",
        "max_power_k = 0\n",
        "for k in range(0,len(n)):\n",
        "  if plot_error_df.test_error.iloc[k] - plot_error_df.test_error.iloc[len(n)-1] > 0.02:\n",
        "    max_power_k = k\n",
        "\n",
        "print(\"The maximal power k such that the test error for n=10×2k is at least 0.02 higher than the test error for the maximal  n, is:\", max_power_k)\n",
        "    "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximal power k such that the test error for n=10×2k is at least 0.02 higher than the test error for the maximal  n, is: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sHedEcwMRV2"
      },
      "source": [
        "n_max = n[-1]\n",
        "number_of_blocks = int(n_max/n[max_power_k])\n",
        "train_set = x_train\n",
        "train_set[\"y\"] = y_train\n",
        "#Calculating the size of each batch\n",
        "size_batch = int(len(train_set)/number_of_blocks)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdyubGgTVCIm"
      },
      "source": [
        "#Spliting to blocks using batch function and running logistic regression model on each block. \n",
        "df_coef = []\n",
        "for block in batch_func(train_set, size_batch):\n",
        "  block = pd.DataFrame(block)\n",
        "  block_x = block.iloc[:,:104]\n",
        "  block_y = block.iloc[:,104]\n",
        "  block_fit = lr.fit(block_x,block_y)\n",
        "  df_coef.append(block_fit.coef_)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8lE9eoMuDEh"
      },
      "source": [
        "#Getting the average of the fitted models coefficients to get a combined model.\n",
        "coef = [x[0] for x in df_coef]\n",
        "coef = pd.DataFrame(coef)\n",
        "model_coef = [coef[i].mean() for i in coef.columns]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAX_b3eBK1NL"
      },
      "source": [
        "#A function that inputs X matrix and vector of betas and predicts the relevant y's for logistic regression using sigmoid function\n",
        "def logistic_predictor(x_matrix, betas):\n",
        "  y = (np.exp(x_matrix@betas))/(1 + (np.exp(x_matrix@betas))) #Applying sigmoid\n",
        "  y = pd.DataFrame(y)\n",
        "  y =  np.where(y < 0.5, 0, 1) #Classifying probabilities to binary values (0,1)\n",
        "  return y"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82sNSQZXmFkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "99b4e893-dc8b-44eb-f4da-7e213f844e4a"
      },
      "source": [
        "#Checking the model with the train set\n",
        "y_avg_train = logistic_predictor(train_x, model_coef)\n",
        "cm = model_results(train_y,y_avg_train)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sn.heatmap(cm, annot=True,fmt=\"d\",annot_kws={\"size\": 16}) # font size\n",
        "plt.xlabel('Predicted Label'); plt.ylabel('True Label');"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.985\n",
            "Recall score: 0.587\n",
            "F1 score: 0.735\n",
            "AUC score: 0.780\n",
            "Accuracy: 0.681\n",
            "Confusion matrix:\n",
            "[[19430   548]\n",
            " [25596 36346]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1tYg2SpNlQh"
      },
      "source": [
        "Pretty low accuracy for the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5GakLlI5F0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "11346d0e-6185-4a14-c02a-0ca3add4d77f"
      },
      "source": [
        "#Checking the model with the test set\n",
        "y_hat_avg = logistic_predictor(x_test, model_coef)\n",
        "cm = model_results(y_test,y_hat_avg)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sn.heatmap(cm, annot=True,fmt=\"d\",annot_kws={\"size\": 16}) # font size\n",
        "plt.xlabel('Predicted Label'); plt.ylabel('True Label');"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.984\n",
            "Recall score: 0.586\n",
            "F1 score: 0.734\n",
            "AUC score: 0.778\n",
            "Accuracy: 0.681\n",
            "Confusion matrix:\n",
            "[[ 6454   192]\n",
            " [ 8328 11776]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yoSaBkINyYl"
      },
      "source": [
        "Pretty low accuracy for the test set as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T7yBF7AN_Cx"
      },
      "source": [
        "As mentioned above, when using the batch method and spliting to blocks and combinig the models of data we lose accuracies in our models. This is the reason that the accuracies here are significantly lower than in the previous subquestion. \n",
        "\n",
        "Although the reason behind the accuracies using the batch method (alongside the combinig of the model) being lower, I did not expect the accuracies to be that low. This raises a question regarding when it is worth to use this method and why should we even use it at all? \n",
        "\n",
        "The answer is when we work with big data. In these cases, we need to save space and time and we preffer \"damaging\" a bit our model accuracy to achieve these crucial goals. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLwy1JITJgLR"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ydldpyMCdXZ"
      },
      "source": [
        "**3.(e) [10 pt] Combining models from different datasets:** \n",
        "\n",
        "* Pick $10$ different categories from the Amazon reviews dataset.  \n",
        "\n",
        "* For each dataset, read a batch of $10,000$ examples and split to train/test randoly with an `80%|20%` ratio as before. \n",
        "*  **Note:** You may pick large categories. **Do not** download the whole file as in  **1.(d)**. Instead, use `readlines` to download only the first $10,000$.\n",
        "\n",
        "* Run a logistic regression model on each category separately, including all the preprocessing steps you have done in question 2: Adding the sentiment features, converting to binary variables, and running `TfidfVectorizer`\n",
        "- Random splitting to train\n",
        "from 2.(d.), . \n",
        "and Report the train/test accuracies in a table. \n",
        "\n",
        "\n",
        "* Finally, average the fitted models coefficients from all categories to get a `combined model`. \n",
        "\n",
        "* Report the train and test accuracy for the `combined model` on the training and test set of each category separately.  \n",
        "\n",
        "* Did adding $\\times10$ more examples help in improving the accuracy compared to fitting each category separately? why do you think this happened?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT7m3aNomyrp"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wokdNMhrm0tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58216b5f-6b7f-42cb-821e-88d9f5dd02cb"
      },
      "source": [
        "ten_categories = list(file_categories_df[\"categories\"][2:22:2])\n",
        "print(\"The 10 categories i chose are:\", ten_categories)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 10 categories i chose are: ['Automotive', 'Beauty', 'Books_01', 'Camera', 'Digital_Ebook_Purchase_01', 'Digital_Software', 'Digital_Video_Games', 'Furniture', 'Grocery', 'Home_Entertainment']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKI1vREuQZL1"
      },
      "source": [
        "Creating a big useful function which reads the first 10,000 rows of a data category and uses the function from previous questions to modify, process and map the relevant data. We get back a dataframe ready for modeling and statistically analyzing.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xq-Wpi9na1b"
      },
      "source": [
        "def reading_dataset(index):\n",
        "\n",
        "  size = 10000000 #bytes \n",
        "  \n",
        "  print('file to read/stream: ', filtered_keys[index][0])\n",
        "  fileToStream = filtered_keys[index][0]\n",
        "\n",
        "  obj = s3conn.Object('amazon-reviews-pds', fileToStream)  # connect to database \n",
        "\n",
        "  with gzip.GzipFile(fileobj=obj.get()[\"Body\"]) as gzipfile:\n",
        "          batch = [i.decode().replace('\"\"','\"').strip().split('\\t') for i in gzipfile.readlines(size)[0:10000]] #Reading only the first 10,000 datapoints for each category\n",
        "  \n",
        "  data_frame = pd.DataFrame(batch, columns = [\"marketplace\", \"customer_id\", \"review_id\", \"product_id\",\"product_parent\", \"product_title\", \"product_category\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\", \"verified_purchase\",\"review_headline\",\"review_body\", \"review_date\"])\n",
        "  data_frame = data_frame.iloc[1:,1:]\n",
        "  \n",
        "  #Using functions from before to get the data we want\n",
        "  data_frame = modifier(data_frame) #Cleaning the data using the modifier function from before\n",
        "  data_frame = sent(data_frame) #Adding sent_score and sent_value as columns in our dataframe\n",
        "  data_frame = modify(data_frame) #Creating \"binstar\" column and classifying variables to numeric type\n",
        "\n",
        "  #Using mapper from before and running TfidfVectorizer\n",
        "  new_mapper_fit = mapper.fit(data_frame)\n",
        "  data_frame = mapper.transform(data_frame) # a numpy array \n",
        "  data_frame = pd.DataFrame(data_frame)\n",
        "\n",
        "  return data_frame"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k959d4qaOrNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8425f1-9102-42b6-e9d5-9b3176e761c6"
      },
      "source": [
        "#Calling the function above for each one of the 10 categories and getting dataframes clean and ready for analysis.\n",
        "Automotive_df = reading_dataset(2)\n",
        "Beauty_df = reading_dataset(4)\n",
        "Books_01_df = reading_dataset(6)\n",
        "Camera_df = reading_dataset(8)\n",
        "Digital_Ebook_Purchase_01_df = reading_dataset(10)\n",
        "Digital_Software_df = reading_dataset(12)\n",
        "Digital_Video_Games_df = reading_dataset(14)\n",
        "Furniture_df = reading_dataset(16)\n",
        "Grocery_df = reading_dataset(18)\n",
        "Home_Entertainment_df = reading_dataset(20)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Automotive_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:16<00:00,  4.67it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:17<00:00,  4.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.77it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.82it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Books_v1_01.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 66: 100%|██████████| 66/66 [01:34<00:00,  1.43s/it]\n",
            "Inferencing on batch 66: 100%|██████████| 66/66 [01:33<00:00,  1.42s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Camera_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:28<00:00,  2.81it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:28<00:00,  2.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:44<00:00,  1.78it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:45<00:00,  1.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:31<00:00,  2.53it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:31<00:00,  2.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.80it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:20<00:00,  3.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Furniture_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:23<00:00,  3.37it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:23<00:00,  3.35it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Grocery_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:19<00:00,  4.03it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:17<00:00,  4.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Home_Entertainment_v1_00.tsv.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:31<00:00,  2.50it/s]\n",
            "Inferencing on batch 79: 100%|██████████| 79/79 [00:31<00:00,  2.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UvuVfP6RWqj"
      },
      "source": [
        "Now, we would create some functions so we can efficiently split, normalize and calculate the accuracies of each dataframe from each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPHHE2765Oi"
      },
      "source": [
        "#Normalizing and spliting the data\n",
        "def norm_and_split(data_frame):\n",
        "  y = data_frame.iloc[:,104]\n",
        "  x = data_frame.iloc[:,:104]\n",
        "\n",
        "  #Normalizing the data\n",
        "  x = preprocessing.scale(x)\n",
        "  x = preprocessing.normalize(x)\n",
        "  x = pd.DataFrame(x)\n",
        "\n",
        "  #spliting the data randomly\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
        "  \n",
        "  return (x_train, x_test, y_train, y_test)\n",
        "\n",
        "#Finding the accuracy of each dataframe using the norm and split function\n",
        "def accuracy_func(data_frame):\n",
        "  x_train, x_test, y_train, y_test = norm_and_split(data_frame)\n",
        "  lr = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
        "  model = lr.fit(x_train,y_train)\n",
        "  pred = model.predict(x_test)\n",
        "  accuracy = accuracy_score(y_test, pred)\n",
        "  return accuracy"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjOgAt65SJY8"
      },
      "source": [
        "Creating a list of the dataframes helps us loop over them. We would also create a list of the dataframes names and find the accuracies of our logistic regression model for each dataframe. Then we can zip them to a dictionary and print a table with the accuracies we got. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbjz84gbG9uU"
      },
      "source": [
        "df_lst = [Automotive_df, Beauty_df , Books_01_df, Camera_df, Digital_Ebook_Purchase_01_df, Digital_Software_df, Digital_Video_Games_df, Furniture_df, Grocery_df, Home_Entertainment_df]\n",
        "df_lst_names = [\"Automotive_df\", \"Beauty_df\" , \"Books_01_df\", \"Camera_df\", \"Digital_Ebook_Purchase_01_df\", \"Digital_Software_df\", \"Digital_Video_Games_df\", \"Furniture_df\", \"Grocery_df\", \"Home_Entertainment_df\"]\n",
        "acc_lst = [accuracy_func(df_lst[i]) for i in range(len(df_lst))]\n",
        "accuracy_table = dict(zip(df_lst_names, acc_lst))\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0M-hBKsDZkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862f79a1-4f5a-4db1-f351-0ff0b2cb5818"
      },
      "source": [
        "from tabulate import tabulate\n",
        "print(\"Accuracy Table:\")\n",
        "print(tabulate(accuracy_table.items(), headers='keys', tablefmt='fancy_grid', showindex=True))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Table:\n",
            "╒════╤══════════════════════════════╤══════════╕\n",
            "│    │ 0                            │        1 │\n",
            "╞════╪══════════════════════════════╪══════════╡\n",
            "│  0 │ Automotive_df                │ 0.903467 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  1 │ Beauty_df                    │ 0.908698 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  2 │ Books_01_df                  │ 0.91114  │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  3 │ Camera_df                    │ 0.922869 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  4 │ Digital_Ebook_Purchase_01_df │ 0.942117 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  5 │ Digital_Software_df          │ 0.866594 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  6 │ Digital_Video_Games_df       │ 0.891791 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  7 │ Furniture_df                 │ 0.918815 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  8 │ Grocery_df                   │ 0.911064 │\n",
            "├────┼──────────────────────────────┼──────────┤\n",
            "│  9 │ Home_Entertainment_df        │ 0.902162 │\n",
            "╘════╧══════════════════════════════╧══════════╛\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCo_TV18O4u0"
      },
      "source": [
        "#Finding coeficients for each dataframe. Same as before only this time we would create a new function so we could loop over the dataframes easily.\n",
        "def coef_df(data_frames_lst):\n",
        "  coef = []\n",
        "  for df in data_frames_lst:\n",
        "    df_x = df.iloc[:,:104]\n",
        "    df_y = df.iloc[:,104]\n",
        "    lr.fit(df_x,df_y)\n",
        "    coef.extend(lr.coef_)\n",
        "\n",
        "  coef = pd.DataFrame(coef)\n",
        "  combined_model = [coef[i].mean() for i in coef.columns]\n",
        "\n",
        "  return combined_model\n",
        "\n",
        "#Calling the function and getting our averaged coeficients\n",
        "combined_model = coef_df(df_lst)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPJo3V71VkIU"
      },
      "source": [
        "#Function that gets data and coeficients and prints out the results of the combined model (both for the train and test sets)\n",
        "def avg_result(data_frame, combined_model):\n",
        "  \n",
        "  x_train, x_test, y_train, y_test = norm_and_split(data_frame)\n",
        "\n",
        "  y_train_combined = logistic_predictor(x_train, combined_model)\n",
        "  print(\"\")\n",
        "  print(\"The model results for the train set is:\")\n",
        "  print(round(accuracy_score(y_train,y_train_combined),4))\n",
        "  \n",
        "  y_test_combined = logistic_predictor(x_test, combined_model)\n",
        "  print(\"\")\n",
        "  print(\"The model results for the test set is:\")\n",
        "  print(round(accuracy_score(y_test, y_test_combined),4))"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktMY75EsbwWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66de636-a2cd-4c02-b5e0-58fd6e265f27"
      },
      "source": [
        "#Looping over the dataframes list and printing each dataframes accuracy result.\n",
        "for i in range(len(df_lst)):\n",
        "  print(\"\")\n",
        "  print(\"The results of the model for\", df_lst_names[i], \"are:\")\n",
        "  avg_result(df_lst[i], combined_model)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The results of the model for Automotive_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5247\n",
            "\n",
            "The model results for the test set is:\n",
            "0.5195\n",
            "\n",
            "The results of the model for Beauty_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5462\n",
            "\n",
            "The model results for the test set is:\n",
            "0.5348\n",
            "\n",
            "The results of the model for Books_01_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.6004\n",
            "\n",
            "The model results for the test set is:\n",
            "0.5937\n",
            "\n",
            "The results of the model for Camera_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5564\n",
            "\n",
            "The model results for the test set is:\n",
            "0.5491\n",
            "\n",
            "The results of the model for Digital_Ebook_Purchase_01_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5771\n",
            "\n",
            "The model results for the test set is:\n",
            "0.5739\n",
            "\n",
            "The results of the model for Digital_Software_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5905\n",
            "\n",
            "The model results for the test set is:\n",
            "0.6052\n",
            "\n",
            "The results of the model for Digital_Video_Games_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5912\n",
            "\n",
            "The model results for the test set is:\n",
            "0.6077\n",
            "\n",
            "The results of the model for Furniture_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.631\n",
            "\n",
            "The model results for the test set is:\n",
            "0.6363\n",
            "\n",
            "The results of the model for Grocery_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5256\n",
            "\n",
            "The model results for the test set is:\n",
            "0.5405\n",
            "\n",
            "The results of the model for Home_Entertainment_df are:\n",
            "\n",
            "The model results for the train set is:\n",
            "0.5832\n",
            "\n",
            "The model results for the test set is:\n",
            "0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3YqQ6JRCNao"
      },
      "source": [
        "As we can see, the accuracies are very low. This makes sense because of the fact that we took the mean of the coeficients of all of the models combined and this is not a good way to fit a model. The reason is due to the fact that each model has unique characteristics and should be fitted specificaly with the relevant coeficients.\n",
        "\n",
        "*This in mind, the accuracies I got here, are too low. The reason is that I probably missed something during my work and could not figure out what was my mistake(after debugging the entire code and trying many things). *\n",
        "\n",
        "*You can check and see that before classifying the y's to binary values, most of the y's are under 0.5 and Or said to leave the threshold as 0.5. I don't think that the problem is with the coefficients and I am waiting for your check to understand what I missed in the process.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-ELzeBtTg0e"
      },
      "source": [
        "### **Part 4: Fitting steaming data using Stochastic Gradient Descent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvUftvuakgFK"
      },
      "source": [
        "While we were able to create a predictive model, we used a small subset of the entire data. Using Colab's available resources, it is impossible to run the model on the entire data. To get around loading the entire data in memory at once, we can use `stochastic gradient descent` to train the model a `(mini) batch` at a time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chw5jz8Gl5U6"
      },
      "source": [
        "**4.(a) [3 pt]** Create an `SGDClassifier` object with the logisitc regression loss. You may choose parameters for learning rate (the step-size at each iteration), penalties etc. <br> \n",
        "See [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.partial_fit) for more details. If you don't understand a parameter, just keep the default value.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq9kXrAKA5nC"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfWmGEi_jfQq"
      },
      "source": [
        "GSDlogred = SGDClassifier(loss='log', penalty='l2', random_state=75 , max_iter=100, verbose=0, tol=0.001, warm_start=True)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO57AD_KXIeQ"
      },
      "source": [
        "Our classifier model needs to remember the results from the last step, hence the *warm start*. Some of the other values are default but I found them important so I wrote them. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr4TIPJzfAFK"
      },
      "source": [
        "**4.(b) [6 pt]**\n",
        "*  For the same `train_set` fitted in **3.(a), 3.(b)**, apply the SGD classifier for $50$ epochs (passes over the entire data) using the `partial_fit` method of the object `GSDlogred` you have created in **4.(a)**. <br>\n",
        "\n",
        "* Plot the loss of the classifier as a function of the number of epochs. Does it seem to converge? \n",
        "\n",
        "*  Compute the test error of the final output classifier. How does it compare to the error in **3.(b)** ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sodn8CDAnLun"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kbtF2JjYPwh"
      },
      "source": [
        "if len(x_train.columns) == 105:\n",
        "  x_train = x_train.drop(columns=\"y\")"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy34JuhvJShc"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "loss = []\n",
        "for i in range(0,50):\n",
        "  GSDlogred.partial_fit(x_train,y_train, classes = np.unique(y_train))\n",
        "  pred = GSDlogred.predict(x_test)\n",
        "  loss.append(metrics.log_loss(pred, y_test))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QdP3MOCQ01XT",
        "outputId": "1d31d953-251e-4b6b-8a4c-6a33d73c641e"
      },
      "source": [
        "plt.plot(loss)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDeDPLjc3mCF"
      },
      "source": [
        "As we can see, the loss of the clasifier does converge to approx 4.55. As we can see in the plot, the graph has a shape which is similar to 1/x but instead of converging to 0 it converges to approx 4.55"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "gZjJ0Deidr2g",
        "outputId": "14215d7b-8491-40cf-9b91-1d908cd2e17d"
      },
      "source": [
        "cm = model_results(y_test, pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sn.heatmap(cm, annot=True,fmt=\"d\",annot_kws={\"size\": 16}) # font size\n",
        "plt.xlabel('Predicted Label'); plt.ylabel('True Label');\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.900\n",
            "Recall score: 0.930\n",
            "F1 score: 0.915\n",
            "AUC score: 0.809\n",
            "Accuracy: 0.870\n",
            "Confusion matrix:\n",
            "[[ 4570  2076]\n",
            " [ 1406 18698]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8rG7Vul34xl",
        "outputId": "745cafb1-ada9-4bc4-c3e4-50597c1e9d04"
      },
      "source": [
        "print(\"The test error in this case is:\",  round(1 - accuracy_score(y_test, pred),3))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test error in this case is: 0.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJIQTXHKmSCm"
      },
      "source": [
        "**4.(c) [6 pt]** Pick one of the six *largest* categories in the AWS dataset. \n",
        "\n",
        "Modify and use the `obj` defined in the cell below, to `stream` (readlines) and loop through the gzip file of this category `100000` bytes at a time, with at least `100` batches (all done inside a `with` connection to the gzip file):  \n",
        "\n",
        "*   Make sure each `batch` is parsed appropriately (as have been done already)\n",
        "*   Create a `pandas` dataframe for each `batch` (within each loop) and print the number of rows (data points) in the `batch`\n",
        "*   Update the model parameters by executing the `GSDlogred.partial_fit` method on each processed batch (apply all the preprocessing steps we did in **Part 2** to get a processed numpy array, and the splitting to train and test sets before training the model as in **Part 3**). <br>\n",
        "For each batch report the test accuracy for this batch, and also the *average* test accuracy over all batches so far. Do you see an improvement as you use more and more batches?\n",
        "\n",
        "**Note:** Make sure that your fitting algorithm uses each data point in the batch only once, as is appropriate for the streaming model. \n",
        "Also make sure that when updating the parameters for each batch, the classifier is initialized with the parameters fitted already using previous batches. \n",
        "Modify the `GSDlogred` object if needed, before looping over batches, to accomodate these changes and other changes needed to deal with the data stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46e3ZfUFA8KB"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdYGYg0r7CVQ",
        "outputId": "a232d91f-a4b2-4e41-a628-b99eb059fb13"
      },
      "source": [
        "large_files = file_categories_df.sort_values(by=['sizeGB'], ascending=False).head(6)\n",
        "print(\"The large file I chose is:\", large_files.iloc[4][0])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The large file I chose is: Music\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JggfYsQCexWb"
      },
      "source": [
        "#Parser function, similar to the reading data fumction from before\n",
        "def music_parser():\n",
        "\n",
        "    maxCount = 100\n",
        "    batch_size = 100000 #bytes \n",
        "\n",
        "    print('file to read/stream: ', filtered_keys[30][0])\n",
        "    fileToStream = filtered_keys[30][0]\n",
        "\n",
        "    obj = s3conn.Object('amazon-reviews-pds', fileToStream)  \n",
        "\n",
        "    GSDlogred = SGDClassifier(loss='log', random_state=15, warm_start=True) \n",
        "\n",
        "    counter = 1\n",
        "    with gzip.GzipFile(fileobj=obj.get()[\"Body\"]) as gzipfile:\n",
        "        while counter <= maxCount:\n",
        "            batch = [i.decode().replace('\"\"','\"').strip().split('\\t') for i in gzipfile.readlines(batch_size)]\n",
        "            data_batch = pd.DataFrame(batch, columns = [\"marketplace\", \"customer_id\", \"review_id\", \"product_id\",\"product_parent\", \"product_title\", \"product_category\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\", \"verified_purchase\",\"review_headline\",\"review_body\", \"review_date\"])\n",
        "            data_batch = data_batch.iloc[1:,1:]\n",
        "\n",
        "  \n",
        "            #Using functions from before to get the data we want\n",
        "            data_batch = modifier(data_batch) #Cleaning the data using the modifier function from before\n",
        "            \n",
        "            #Adding sent_score and sent_value as columns in our dataframe\n",
        "            sentences = np.array(data_batch[\"reviews_processed\"])\n",
        "            sentences = [Sentence(item) for item in sentences]\n",
        "            classifier.predict(sentences)\n",
        "            values = []\n",
        "            for i in range(len(sentences)):\n",
        "                values.append([sentences[i].labels[0].value,sentences[i].labels[0].score])\n",
        "            values = pd.DataFrame(values)\n",
        "\n",
        "            # Assign to data frame\n",
        "            data_batch[\"sent_value\"] = values.iloc[:,0]\n",
        "            data_batch[\"sent_score\"] = values.iloc[:,1]\n",
        "            \n",
        "            data_batch = modify(data_batch) #Creating \"binstar\" column and classifying variables to numeric type\n",
        "\n",
        "            #Using mapper from before and running TfidfVectorizer\n",
        "            music_mapper_fit = mapper.fit(data_batch)\n",
        "            data_batch = mapper.transform(data_batch) # a numpy array \n",
        "            data_batch = pd.DataFrame(data_batch)\n",
        "            \n",
        "            x_train, x_test, y_train, y_test = norm_and_split(data_batch)\n",
        "            GSDlogred.partial_fit(x_train,y_train, classes = [0,1])\n",
        "            y_hat = GSDlogred.predict(x_test)\n",
        "            avg_acc = round(accuracy_score(y_hat,y_test),3)\n",
        "            \n",
        "            if counter > 1:\n",
        "              sum_so_far = avg_acc*counter\n",
        "              print(\"For batch number \",counter,\",the number of lines is:\", len(data_batch),\"the accuracy score is:\", round((sum_so_far - last_sum_acc),3))\n",
        "              print(\"The average test accuracy for all batches so far is\", avg_acc)\n",
        "              last_sum_acc = sum_so_far\n",
        "                 \n",
        "            else: \n",
        "              sum_so_far = avg_acc\n",
        "              print(\"The for the batch number 1 the accuracy score is:\", avg_acc)\n",
        "              print(\"The number of lines of this batch is: \", len(data_batch))\n",
        "              last_sum_acc = sum_so_far\n",
        "\n",
        "            counter += 1\n",
        "            \n",
        "              "
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc22MEfMfv3o",
        "outputId": "53be7784-6c10-4286-c11a-33e1b6daab69"
      },
      "source": [
        "Music_acc = music_parser()\n",
        "Music_acc"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file to read/stream:  tsv/amazon_reviews_us_Music_v1_00.tsv.gz\n",
            "The for the batch number 1 the accuracy score is: 0.969\n",
            "The number of lines of this batch is:  325\n",
            "For batch number  2 ,the number of lines is: 269 the accuracy score is: 0.845\n",
            "The average test accuracy for all batches so far is 0.907\n",
            "For batch number  3 ,the number of lines is: 322 the accuracy score is: 1.0\n",
            "The average test accuracy for all batches so far is 0.938\n",
            "For batch number  4 ,the number of lines is: 212 the accuracy score is: 1.186\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  5 ,the number of lines is: 256 the accuracy score is: 0.81\n",
            "The average test accuracy for all batches so far is 0.962\n",
            "For batch number  6 ,the number of lines is: 298 the accuracy score is: 0.89\n",
            "The average test accuracy for all batches so far is 0.95\n",
            "For batch number  7 ,the number of lines is: 274 the accuracy score is: 1.048\n",
            "The average test accuracy for all batches so far is 0.964\n",
            "For batch number  8 ,the number of lines is: 309 the accuracy score is: 0.996\n",
            "The average test accuracy for all batches so far is 0.968\n",
            "For batch number  9 ,the number of lines is: 260 the accuracy score is: 0.563\n",
            "The average test accuracy for all batches so far is 0.923\n",
            "For batch number  10 ,the number of lines is: 248 the accuracy score is: 0.093\n",
            "The average test accuracy for all batches so far is 0.84\n",
            "For batch number  11 ,the number of lines is: 291 the accuracy score is: 1.665\n",
            "The average test accuracy for all batches so far is 0.915\n",
            "For batch number  12 ,the number of lines is: 231 the accuracy score is: 1.683\n",
            "The average test accuracy for all batches so far is 0.979\n",
            "For batch number  13 ,the number of lines is: 253 the accuracy score is: 0.485\n",
            "The average test accuracy for all batches so far is 0.941\n",
            "For batch number  14 ,the number of lines is: 326 the accuracy score is: 0.703\n",
            "The average test accuracy for all batches so far is 0.924\n",
            "For batch number  15 ,the number of lines is: 217 the accuracy score is: 1.389\n",
            "The average test accuracy for all batches so far is 0.955\n",
            "For batch number  16 ,the number of lines is: 295 the accuracy score is: 0.587\n",
            "The average test accuracy for all batches so far is 0.932\n",
            "For batch number  17 ,the number of lines is: 250 the accuracy score is: 1.408\n",
            "The average test accuracy for all batches so far is 0.96\n",
            "For batch number  18 ,the number of lines is: 260 the accuracy score is: -0.39\n",
            "The average test accuracy for all batches so far is 0.885\n",
            "For batch number  19 ,the number of lines is: 270 the accuracy score is: 2.709\n",
            "The average test accuracy for all batches so far is 0.981\n",
            "For batch number  20 ,the number of lines is: 245 the accuracy score is: -0.679\n",
            "The average test accuracy for all batches so far is 0.898\n",
            "For batch number  21 ,the number of lines is: 230 the accuracy score is: 1.213\n",
            "The average test accuracy for all batches so far is 0.913\n",
            "For batch number  22 ,the number of lines is: 205 the accuracy score is: 2.299\n",
            "The average test accuracy for all batches so far is 0.976\n",
            "For batch number  23 ,the number of lines is: 216 the accuracy score is: 0.493\n",
            "The average test accuracy for all batches so far is 0.955\n",
            "For batch number  24 ,the number of lines is: 170 the accuracy score is: 2.035\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  25 ,the number of lines is: 202 the accuracy score is: -0.825\n",
            "The average test accuracy for all batches so far is 0.927\n",
            "For batch number  26 ,the number of lines is: 289 the accuracy score is: 1.031\n",
            "The average test accuracy for all batches so far is 0.931\n",
            "For batch number  27 ,the number of lines is: 296 the accuracy score is: 1.444\n",
            "The average test accuracy for all batches so far is 0.95\n",
            "For batch number  28 ,the number of lines is: 220 the accuracy score is: 1.706\n",
            "The average test accuracy for all batches so far is 0.977\n",
            "For batch number  29 ,the number of lines is: 241 the accuracy score is: -3.083\n",
            "The average test accuracy for all batches so far is 0.837\n",
            "For batch number  30 ,the number of lines is: 226 the accuracy score is: 2.457\n",
            "The average test accuracy for all batches so far is 0.891\n",
            "For batch number  31 ,the number of lines is: 281 the accuracy score is: 1.542\n",
            "The average test accuracy for all batches so far is 0.912\n",
            "For batch number  32 ,the number of lines is: 240 the accuracy score is: 2.384\n",
            "The average test accuracy for all batches so far is 0.958\n",
            "For batch number  33 ,the number of lines is: 217 the accuracy score is: 0.859\n",
            "The average test accuracy for all batches so far is 0.955\n",
            "For batch number  34 ,the number of lines is: 238 the accuracy score is: 0.377\n",
            "The average test accuracy for all batches so far is 0.938\n",
            "For batch number  35 ,the number of lines is: 249 the accuracy score is: 2.408\n",
            "The average test accuracy for all batches so far is 0.98\n",
            "For batch number  36 ,the number of lines is: 224 the accuracy score is: -1.504\n",
            "The average test accuracy for all batches so far is 0.911\n",
            "For batch number  37 ,the number of lines is: 238 the accuracy score is: 4.204\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  38 ,the number of lines is: 269 the accuracy score is: 0.278\n",
            "The average test accuracy for all batches so far is 0.981\n",
            "For batch number  39 ,the number of lines is: 277 the accuracy score is: 1.722\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  40 ,the number of lines is: 282 the accuracy score is: -1.8\n",
            "The average test accuracy for all batches so far is 0.93\n",
            "For batch number  41 ,the number of lines is: 329 the accuracy score is: 2.57\n",
            "The average test accuracy for all batches so far is 0.97\n",
            "For batch number  42 ,the number of lines is: 258 the accuracy score is: 2.23\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  43 ,the number of lines is: 289 the accuracy score is: -2.698\n",
            "The average test accuracy for all batches so far is 0.914\n",
            "For batch number  44 ,the number of lines is: 260 the accuracy score is: 0.474\n",
            "The average test accuracy for all batches so far is 0.904\n",
            "For batch number  45 ,the number of lines is: 271 the accuracy score is: 1.129\n",
            "The average test accuracy for all batches so far is 0.909\n",
            "For batch number  46 ,the number of lines is: 257 the accuracy score is: 3.347\n",
            "The average test accuracy for all batches so far is 0.962\n",
            "For batch number  47 ,the number of lines is: 243 the accuracy score is: 0.821\n",
            "The average test accuracy for all batches so far is 0.959\n",
            "For batch number  48 ,the number of lines is: 325 the accuracy score is: 2.207\n",
            "The average test accuracy for all batches so far is 0.985\n",
            "For batch number  49 ,the number of lines is: 312 the accuracy score is: -2.151\n",
            "The average test accuracy for all batches so far is 0.921\n",
            "For batch number  50 ,the number of lines is: 197 the accuracy score is: 3.621\n",
            "The average test accuracy for all batches so far is 0.975\n",
            "For batch number  51 ,the number of lines is: 301 the accuracy score is: 2.25\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  52 ,the number of lines is: 231 the accuracy score is: -3.42\n",
            "The average test accuracy for all batches so far is 0.915\n",
            "For batch number  53 ,the number of lines is: 160 the accuracy score is: 2.134\n",
            "The average test accuracy for all batches so far is 0.938\n",
            "For batch number  54 ,the number of lines is: 229 the accuracy score is: 4.286\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  55 ,the number of lines is: 258 the accuracy score is: -1.09\n",
            "The average test accuracy for all batches so far is 0.962\n",
            "For batch number  56 ,the number of lines is: 234 the accuracy score is: 0.682\n",
            "The average test accuracy for all batches so far is 0.957\n",
            "For batch number  57 ,the number of lines is: 232 the accuracy score is: 0.957\n",
            "The average test accuracy for all batches so far is 0.957\n",
            "For batch number  58 ,the number of lines is: 219 the accuracy score is: 2.117\n",
            "The average test accuracy for all batches so far is 0.977\n",
            "For batch number  59 ,the number of lines is: 258 the accuracy score is: -1.088\n",
            "The average test accuracy for all batches so far is 0.942\n",
            "For batch number  60 ,the number of lines is: 161 the accuracy score is: 2.622\n",
            "The average test accuracy for all batches so far is 0.97\n",
            "For batch number  61 ,the number of lines is: 206 the accuracy score is: 2.8\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  62 ,the number of lines is: 239 the accuracy score is: -4.146\n",
            "The average test accuracy for all batches so far is 0.917\n",
            "For batch number  63 ,the number of lines is: 238 the accuracy score is: 3.5\n",
            "The average test accuracy for all batches so far is 0.958\n",
            "For batch number  64 ,the number of lines is: 239 the accuracy score is: -0.322\n",
            "The average test accuracy for all batches so far is 0.938\n",
            "For batch number  65 ,the number of lines is: 169 the accuracy score is: 1.133\n",
            "The average test accuracy for all batches so far is 0.941\n",
            "For batch number  66 ,the number of lines is: 275 the accuracy score is: 1.205\n",
            "The average test accuracy for all batches so far is 0.945\n",
            "For batch number  67 ,the number of lines is: 243 the accuracy score is: -2.204\n",
            "The average test accuracy for all batches so far is 0.898\n",
            "For batch number  68 ,the number of lines is: 202 the accuracy score is: 6.202\n",
            "The average test accuracy for all batches so far is 0.976\n",
            "For batch number  69 ,the number of lines is: 237 the accuracy score is: -4.544\n",
            "The average test accuracy for all batches so far is 0.896\n",
            "For batch number  70 ,the number of lines is: 241 the accuracy score is: 6.776\n",
            "The average test accuracy for all batches so far is 0.98\n",
            "For batch number  71 ,the number of lines is: 179 the accuracy score is: -3.493\n",
            "The average test accuracy for all batches so far is 0.917\n",
            "For batch number  72 ,the number of lines is: 232 the accuracy score is: 3.797\n",
            "The average test accuracy for all batches so far is 0.957\n",
            "For batch number  73 ,the number of lines is: 276 the accuracy score is: -1.087\n",
            "The average test accuracy for all batches so far is 0.929\n",
            "For batch number  74 ,the number of lines is: 245 the accuracy score is: 3.149\n",
            "The average test accuracy for all batches so far is 0.959\n",
            "For batch number  75 ,the number of lines is: 301 the accuracy score is: -0.916\n",
            "The average test accuracy for all batches so far is 0.934\n",
            "For batch number  76 ,the number of lines is: 324 the accuracy score is: 1.238\n",
            "The average test accuracy for all batches so far is 0.938\n",
            "For batch number  77 ,the number of lines is: 260 the accuracy score is: 1.246\n",
            "The average test accuracy for all batches so far is 0.942\n",
            "For batch number  78 ,the number of lines is: 281 the accuracy score is: 2.736\n",
            "The average test accuracy for all batches so far is 0.965\n",
            "For batch number  79 ,the number of lines is: 337 the accuracy score is: 0.254\n",
            "The average test accuracy for all batches so far is 0.956\n",
            "For batch number  80 ,the number of lines is: 285 the accuracy score is: 0.236\n",
            "The average test accuracy for all batches so far is 0.947\n",
            "For batch number  81 ,the number of lines is: 275 the accuracy score is: 0.785\n",
            "The average test accuracy for all batches so far is 0.945\n",
            "For batch number  82 ,the number of lines is: 324 the accuracy score is: 0.371\n",
            "The average test accuracy for all batches so far is 0.938\n",
            "For batch number  83 ,the number of lines is: 304 the accuracy score is: -2.05\n",
            "The average test accuracy for all batches so far is 0.902\n",
            "For batch number  84 ,the number of lines is: 298 the accuracy score is: 4.934\n",
            "The average test accuracy for all batches so far is 0.95\n",
            "For batch number  85 ,the number of lines is: 304 the accuracy score is: 1.035\n",
            "The average test accuracy for all batches so far is 0.951\n",
            "For batch number  86 ,the number of lines is: 209 the accuracy score is: -5.069\n",
            "The average test accuracy for all batches so far is 0.881\n",
            "For batch number  87 ,the number of lines is: 299 the accuracy score is: 8.363\n",
            "The average test accuracy for all batches so far is 0.967\n",
            "For batch number  88 ,the number of lines is: 264 the accuracy score is: 0.527\n",
            "The average test accuracy for all batches so far is 0.962\n",
            "For batch number  89 ,the number of lines is: 285 the accuracy score is: 2.742\n",
            "The average test accuracy for all batches so far is 0.982\n",
            "For batch number  90 ,the number of lines is: 270 the accuracy score is: 2.602\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  91 ,the number of lines is: 269 the accuracy score is: -2.367\n",
            "The average test accuracy for all batches so far is 0.963\n",
            "For batch number  92 ,the number of lines is: 335 the accuracy score is: 1.607\n",
            "The average test accuracy for all batches so far is 0.97\n",
            "For batch number  93 ,the number of lines is: 267 the accuracy score is: -3.122\n",
            "The average test accuracy for all batches so far is 0.926\n",
            "For batch number  94 ,the number of lines is: 246 the accuracy score is: 2.242\n",
            "The average test accuracy for all batches so far is 0.94\n",
            "For batch number  95 ,the number of lines is: 289 the accuracy score is: 1.7\n",
            "The average test accuracy for all batches so far is 0.948\n",
            "For batch number  96 ,the number of lines is: 271 the accuracy score is: 4.212\n",
            "The average test accuracy for all batches so far is 0.982\n",
            "For batch number  97 ,the number of lines is: 267 the accuracy score is: 0.885\n",
            "The average test accuracy for all batches so far is 0.981\n",
            "For batch number  98 ,the number of lines is: 298 the accuracy score is: -2.057\n",
            "The average test accuracy for all batches so far is 0.95\n",
            "For batch number  99 ,the number of lines is: 315 the accuracy score is: 5.9\n",
            "The average test accuracy for all batches so far is 1.0\n",
            "For batch number  100 ,the number of lines is: 206 the accuracy score is: -1.4\n",
            "The average test accuracy for all batches so far is 0.976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE9tg23BkrkZ"
      },
      "source": [
        "As we can, there is an improvement as we use more and more batches. Furthermore, the average accuracy score for all batches converges with the accuracy of the last element. \n",
        "\n",
        "*Note that, the scores converged up until the last time I run the code when something went wrong and I failed to find the sorce of the problem.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtqHLksmulek"
      },
      "source": [
        "**4.(d) [6 pt] Open Question** How can you improve the classifier? Suggest and implement a way to train a classifier such that the test error on the category you picked in question **1.(d)**  will improve compared to all previous results for this test set. \n",
        "\n",
        "You can be creative: use additional data, fit additional models (e.g. nonlinear), change the training algorithm, etc. \n",
        "\n",
        "Report the running time and the test accuracy of your algorithm \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwtqX74Usw8L"
      },
      "source": [
        "**Solution:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "224G1OtJv7IV"
      },
      "source": [
        "The classifier can be improved using *C-Support Vector Classification*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqx7hMK_n5b-"
      },
      "source": [
        "new_x = X\n",
        "new_y = binstar\n",
        "\n",
        "new_x = preprocessing.normalize(new_x)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmmzESBBxI23"
      },
      "source": [
        "#spliting the data to train and test\n",
        "new_x_train, new_x_test, new_y_train, new_y_test = train_test_split(new_x, new_y, test_size=0.2, random_state=42) #spliting the data randomly"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5FArw8rL09Z",
        "outputId": "4cdc646c-56d0-42c9-931d-65c4122183b8"
      },
      "source": [
        "#Fitting Support Vector Classification\n",
        "\n",
        "from sklearn import svm\n",
        "svm_classifier = svm.SVC()\n",
        "svm_model_classifier = svm_classifier.fit(x_train, y_train)\n",
        "svm_model_score = svm_model_classifier.score(x_test, y_test)\n",
        "print('The accuracy from the SVM classifier model for my is: ', round(svm_model_score,3))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy from the SVM classifier model for my is:  0.903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSBGSb1VD_FT"
      },
      "source": [
        "Support vector machines(svm) allows missclassifications by having a **soft margin**. A soft margin is the distance between the observations and the threshold and the best soft margin is chosen by cross validation. When we use a soft margin to determine the location of a threshold then we are using a *Soft Margin Classifier*, which is a **Support Vector Classifier**, to classify observations. In our case, the support vector classifier is a hyperplane (flat affine subspace) and the running time to fit the training data is longer than before(due to cross validation, etc.).\n",
        "\n",
        "Note that the benefit we gain by using this method is that Support Vector Classifiers know how to handle outliers and because they allow missclassifications, they can handle overlapping classifications.\n",
        "\n",
        "Support vector machines use *Kernel Functions* to systematically find SVC in higher dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZPeZgkDt2JI"
      },
      "source": [
        "### **Good Luck!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gavd5bF42T8I",
        "outputId": "a1a9acfd-48ed-4b6b-acb6-1aacd3a76ccd"
      },
      "source": [
        "!jupyter nbconvert --to html 204589949.ipynb\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook 204589949.ipynb to html\n",
            "[NbConvertApp] Writing 643454 bytes to 204589949.html\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}